{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import yaml\n",
    "from dlkit import models\n",
    "from dlkit.criterions import Criterion\n",
    "from estimator import Estimator\n",
    "from PIL import Image\n",
    "from preprocessing.dataloader import LaparoDataset, NpLaparoDataset\n",
    "from preprocessing.transformer import ScaleTransformer\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchsummary import summary\n",
    "from torchvision.transforms import Compose, Normalize, Resize, ToTensor\n",
    "from tqdm import tqdm, trange\n",
    "from utils import geometry, modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\envs\\dl\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def is_notebook():\n",
    "    \"\"\"Determine wheather is the environment Jupyter Notebook\"\"\"\n",
    "    if \"get_ipython\" not in globals():\n",
    "        # Python shell\n",
    "        return False\n",
    "    env_name = get_ipython().__class__.__name__\n",
    "    if env_name == \"TerminalInteractiveShell\":\n",
    "        # IPython shell\n",
    "        return False\n",
    "    # Jupyter Notebook\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"ds_num\", type=int, help=\"dataset number\")\n",
    "    parser.add_argument(\"model\", help=\"model name\")\n",
    "    parser.add_argument(\"-b\", \"--batch-size\", default=16, type=int, help=\"batch size\")\n",
    "    parser.add_argument(\"-e\", \"--n_epochs\", default=100, type=int, help=\"epochs\")\n",
    "    parser.add_argument(\"-d\", \"--device\", default=0, type=int)\n",
    "    parser.add_argument(\"-try\", \"--n_trials\", default=3, type=int)\n",
    "    parser.add_argument(\n",
    "        \"--pretrained\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Use the model that is pretrained by myself\",\n",
    "    )\n",
    "    parser.add_argument(\"-w\", \"--n_workers\", default=4, type=int)\n",
    "    parser.add_argument(\"-exp\", \"--exp_name\", default=\"Debug\")\n",
    "    parser.add_argument(\"--a1\", default=1.0, type=float, help=\"Coefficient of l_2d\")\n",
    "    parser.add_argument(\"--a2\", default=1.0, type=float, help=\"Coefficient of l_orient\")\n",
    "    parser.add_argument(\"--a3\", default=1.0, type=float, help=\"Coefficient of l_phi\")\n",
    "    parser.add_argument(\"--a4\", default=1.0, type=float, help=\"Coefficient of l_gamma\")\n",
    "    parser.add_argument('--optuna', action='store_true', help='Hyperparameter optimization [False]')\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_notebook():\n",
    "    cfg = config().parse_args(\n",
    "        args=[\n",
    "            \"24\",\n",
    "            \"res50\",\n",
    "            \"-b\",\n",
    "            \"16\",\n",
    "            \"-e\",\n",
    "            \"20\",\n",
    "            \"--n_trials\",\n",
    "            \"20\",\n",
    "#             \"-exp\",\n",
    "#             \"Pose Estimation\",\n",
    "        ]\n",
    "    )\n",
    "else:\n",
    "    cfg = config().parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, exp_name=cfg.exp_name):\n",
    "\n",
    "        self.device = torch.device(\n",
    "            \"cuda:{}\".format(cfg.device) if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "        self.params = [\"trans3d\", \"trans2d\", \"orient\", \"roll\", \"joint\"]\n",
    "        self.scaler = ScaleTransformer(cfg.ds_num)\n",
    "\n",
    "        self.model = model\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        self.loss_weights = {\n",
    "            \"trans3d\": 1.0,\n",
    "            \"trans2d\": cfg.a1,\n",
    "            \"orient\": cfg.a2,\n",
    "            \"roll\": cfg.a3,\n",
    "            \"joint\": cfg.a4,\n",
    "        }\n",
    "\n",
    "        #         TODO: Read from model_config.yaml\n",
    "        #         summary(self.model, (3, 224, 224))\n",
    "\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        mlflow.set_experiment(cfg.exp_name)\n",
    "\n",
    "    def run(self, trial):\n",
    "        \"\"\"\n",
    "        Return:\n",
    "            Best epoch loss through one trial\n",
    "\n",
    "        Execute learning with fixed hyper parameters.\n",
    "        \"\"\"\n",
    "\n",
    "        min_loss = np.Inf\n",
    "\n",
    "        with mlflow.start_run():\n",
    "            for key, value in vars(cfg).items():\n",
    "                mlflow.log_param(key, value)\n",
    "\n",
    "            lr = self._get_lr(trial)\n",
    "            optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
    "            criterions = self._get_criterion(trial)\n",
    "\n",
    "            with trange(cfg.n_epochs) as epoch_bar:\n",
    "                for epoch in epoch_bar:\n",
    "                    for phase in [\"train\", \"val\"]:\n",
    "                        epoch_bar.set_description(\n",
    "                            \"[{}] Epoch {}\".format(phase.title().rjust(5), epoch + 1)\n",
    "                        )\n",
    "                        epoch_loss = self._train(epoch, phase, criterions, optimizer)\n",
    "                        epoch_bar.set_postfix(loss=epoch_loss)\n",
    "\n",
    "                        # Log weights when the minimum loss is updated\n",
    "                        if phase == \"val\" and epoch_loss < min_loss:\n",
    "                            min_loss = epoch_loss\n",
    "\n",
    "                            mlflow.pytorch.log_model(self.model, \"best_model\")\n",
    "                            mlflow.log_artifacts(output_dir, artifact_path=\"best_model\")\n",
    "                            mlflow.log_metric(\"best epoch\", epoch + 1)\n",
    "\n",
    "            # Save weights\n",
    "            torch.save(model.state_dict(), output_dir + \"/weight.pth\")\n",
    "            mlflow.pytorch.log_model(self.model, \"model\")\n",
    "\n",
    "            self._test()\n",
    "\n",
    "            mlflow.log_artifacts(output_dir, artifact_path=\"model\")\n",
    "\n",
    "        return min_loss\n",
    "\n",
    "    def _train(self, epoch, phase, criterions, optimizer=None):\n",
    "\n",
    "        if phase == \"train\":\n",
    "            self.model.train()\n",
    "\n",
    "        else:\n",
    "            self.model.eval()\n",
    "\n",
    "        sum_train_loss = torch.zeros(6).to(self.device)\n",
    "        sum_val_loss = torch.zeros(6).to(self.device)\n",
    "        sum_loss_dict = {\"train\": sum_train_loss, \"val\": sum_val_loss}\n",
    "        epoch_loss_dict = {\"train\": None, \"val\": None}\n",
    "\n",
    "        for inputs, targets in dataloader_dict[phase]:\n",
    "\n",
    "            inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "\n",
    "            with torch.set_grad_enabled(phase == \"train\"):\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                pred = self._split_param(outputs)\n",
    "                label = self._split_param(targets)\n",
    "\n",
    "                loss = 0.0\n",
    "                for param, criterion in criterions.items():\n",
    "                    param_loss = criterion(pred[param], label[param])\n",
    "                    loss += self.loss_weights[param] * param_loss\n",
    "\n",
    "                    sum_loss_dict[phase][self.params.index(param) + 1] += param_loss\n",
    "\n",
    "                sum_loss_dict[phase][0] += loss\n",
    "\n",
    "                errors = calc_errors(pred, label, self.scaler)\n",
    "\n",
    "                # Update weights\n",
    "                if phase == \"train\":\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "        # Calculate the loss through one epoch\n",
    "        epoch_loss_dict[phase] = sum_loss_dict[\n",
    "            phase\n",
    "        ].detach().cpu().numpy().copy() / len(dataloader_dict[phase])\n",
    "\n",
    "        logparam_list = [\"all\", *self.params]\n",
    "        for i, param_name in enumerate(logparam_list):\n",
    "            self._log_scalar(\n",
    "                \"Loss_{}/{}\".format(param_name.title(), phase),\n",
    "                epoch_loss_dict[phase][i],\n",
    "                epoch,\n",
    "            )\n",
    "\n",
    "        return epoch_loss_dict[phase][0]\n",
    "\n",
    "    def _test(self):\n",
    "        print(\"\\n\\nStart Testing...\\n\")\n",
    "\n",
    "        run_uri = mlflow.get_artifact_uri() + \"/model\"\n",
    "        estimator = Estimator(\n",
    "            mode=2, ds_num=cfg.ds_num, run_uri=run_uri, transform=transform\n",
    "        )\n",
    "        target_df = val_ds.dataframe.drop(columns=[\"alpha\", \"beta\"])\n",
    "        target_df[\"z\"] = -target_df[\"z\"]\n",
    "        value_list = []\n",
    "        for i in trange(len(target_df)):\n",
    "            im_path = \"./Database/ds_{:03d}/val/img_{:05d}.jpg\".format(\n",
    "                cfg.ds_num, i + 1\n",
    "            )\n",
    "            im = Image.open(im_path)\n",
    "            value = estimator(im)\n",
    "            value_list.append(value)\n",
    "\n",
    "        columns = [\"x\", \"y\", \"z\", \"x_2d\", \"y_2d\", \"nx\", \"ny\", \"nz\", \"gamma\", \"phi\"]\n",
    "        pred_df = pd.DataFrame(value_list, columns=columns)\n",
    "        pred_df.to_csv(output_dir + \"/pred_{:03d}.csv\".format(cfg.ds_num))\n",
    "\n",
    "    #         error_df = (target_df - pred_df).rename(columns=lambda x: \"e_\" + x)\n",
    "    #         result = pred_df.join(error_df)\n",
    "    #         save_path = mlflow.get_artifact_uri()\n",
    "\n",
    "    #     analyzer(result, target_df, save_path, conf.ds_num, resize_shape)\n",
    "\n",
    "    def _get_lr(self, trial):\n",
    "        lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-1)\n",
    "        mlflow.log_param(\"lr\", lr)\n",
    "\n",
    "        return lr\n",
    "\n",
    "    def _get_criterion(self, trial):\n",
    "        trans3d = [\"mae\", \"mse\", \"huber\"]\n",
    "        trans2d = [\"mae\", \"mse\", \"huber\"]\n",
    "        orient = [\"mae\", \"mse\", \"huber\", \"cos\"]\n",
    "        roll = [\"mae\", \"mse\", \"huber\"]\n",
    "        joint = [\"mae\", \"mse\", \"huber\"]\n",
    "        criterion_list = [trans3d, trans2d, orient, roll, joint]\n",
    "        criterions = dict()\n",
    "        for param, criterion in zip(self.params, criterion_list):\n",
    "            c = trial.suggest_categorical(param, criterion)\n",
    "            mlflow.log_param(param, c)\n",
    "            criterions[param] = Criterion(mode=c)\n",
    "\n",
    "        return criterions\n",
    "\n",
    "    def _split_param(self, values):\n",
    "        position = self.scaler.inverse_transform(values.detach().cpu())[:, :3]\n",
    "        value_dict = {\n",
    "            \"trans3d\": values[:, :3],\n",
    "            \"trans2d\": geometry.project_onto_plane(  # TODO: Read from config\n",
    "                torch.from_numpy(position),\n",
    "                a_ratio=self.scaler.aspect,\n",
    "                fov=self.scaler.fov,\n",
    "                is_batch=True,\n",
    "            ).to(self.device),\n",
    "            \"orient\": values[:, 3:6],\n",
    "            \"roll\": values[:, 6:8],\n",
    "            \"joint\": values[:, 8].view(-1, 1),\n",
    "        }\n",
    "\n",
    "        return value_dict\n",
    "\n",
    "    def _log_scalar(self, name, value, step):\n",
    "        \"\"\"\n",
    "        Log a scalar value to both MLflow and TensorBoard\n",
    "        \"\"\"\n",
    "        writer.add_scalar(name, value, step)\n",
    "        mlflow.log_metric(name, value, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_errors(pred, label, rescaler):\n",
    "    \"\"\"\n",
    "    Return:\n",
    "    [x, y, z, x_2d, y_2d, nx, ny, nz, gamma_s, gamma_c, phi, trans3d, trans2d, orient, roll, joint]\n",
    "    \"\"\"\n",
    "\n",
    "    # Denormalize outputs\n",
    "    transformed_pred = rescaler.inverse_transform(pred, size=resize_shape)\n",
    "    transformed_label = rescaler.inverse_transform(label, size=resize_shape)\n",
    "\n",
    "    #     print(\"\\n-------------\\n\", transformed_pred, \"\\n+++++++++++++\\n\", transformed_label)\n",
    "\n",
    "    trans2d_pred = geometry.project_onto_plane(\n",
    "        transformed_pred[:, :3],\n",
    "        a_ratio=rescaler.aspect,\n",
    "        fov=rescaler.fov,\n",
    "        is_batch=True,\n",
    "    )\n",
    "    trans2d_label = geometry.project_onto_plane(\n",
    "        transformed_label[:, :3],\n",
    "        a_ratio=rescaler.aspect,\n",
    "        fov=rescaler.fov,\n",
    "        is_batch=True,\n",
    "    )\n",
    "\n",
    "    roll_pred = geometry.sc2deg(transformed_pred[:, 6], transformed_pred[:, 7])\n",
    "    roll_label = geometry.sc2deg(transformed_label[:, 6], transformed_label[:, 7])\n",
    "\n",
    "    # Calculate errors\n",
    "    transformed_error = transformed_pred - transformed_label\n",
    "    trans3d_error = transformed_error[:, :3].norm(dim=1, keepdim=True).mean()\n",
    "    trans2d_error = (\n",
    "        (trans2d_pred - trans2d_label).norm(dim=1, keepdim=True) * resize_shape[0]\n",
    "    ).mean()\n",
    "    similarity = torch.nn.CosineSimilarity(dim=1)\n",
    "    orient_error = (\n",
    "        torch.rad2deg(similarity(transformed_pred[:, 3:6], transformed_label[:, 3:6]))\n",
    "        .abs()\n",
    "        .mean()\n",
    "    )\n",
    "    roll_error = geometry.scale180(roll_pred - roll_label).mean()\n",
    "    joint_error = geometry.scale180(transformed_error[:, 8]).mean()\n",
    "\n",
    "\n",
    "#     print(\n",
    "#         \"error\\n\",\n",
    "#         transformed_error,\n",
    "#         \"\\nem\\n\",\n",
    "#         transformed_error.mean(dim=0),\n",
    "#         \"\\n3\\n\",\n",
    "#         trans3d_error,\n",
    "#         \"\\n2\\n\",\n",
    "#         trans2d_error,\n",
    "#         \"\\no\\n\",\n",
    "#         orient_error,\n",
    "#         \"\\nr\\n\",\n",
    "#         roll_error,\n",
    "#         \"\\nj\\n\",\n",
    "#         joint_error,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_config():\n",
    "    with open(\"./dlkit/model_config.yaml\") as m_config:\n",
    "        m_cfg = yaml.load(m_config)\n",
    "        m = m_cfg[cfg.model][\"name\"]\n",
    "        input_size = m_cfg[cfg.model][\"input_size\"]\n",
    "        return m, input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# TODO: Read from model_config.yaml and ds_config.yaml\n",
    "with open(\"./Database/ds_{:03d}/ds_config.yaml\".format(cfg.ds_num)) as f:\n",
    "    ds_config = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "\n",
    "with open(\"./dlkit/model_config.yaml\") as f:\n",
    "    model_config = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "    resize_shape = model_config[cfg.model][\"input_size\"]\n",
    "\n",
    "if cfg.model == \"res50\":\n",
    "    cmean = [0.485, 0.456, 0.406]\n",
    "    cstd = [0.229, 0.224, 0.225]\n",
    "    model = models.ResNet50()\n",
    "\n",
    "elif cfg.model == \"res50_448\":\n",
    "    cmean = ds_config[\"color\"][\"mean\"]\n",
    "    cstd = ds_config[\"color\"][\"std\"]\n",
    "    model = models.ResNet50_448()\n",
    "\n",
    "transform = Compose([Resize(resize_shape), ToTensor(), Normalize(cmean, cstd)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting a dataset and dataeset loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = NpLaparoDataset(phase=\"train\", ds_num=cfg.ds_num, input_size=resize_shape)\n",
    "val_ds = NpLaparoDataset(phase=\"val\", ds_num=cfg.ds_num, input_size=resize_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\envs\\dl\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# train_ds = LaparoDataset(phase=\"train\", transform=transform, ds_num=cfg.ds_num)\n",
    "# val_ds = LaparoDataset(phase=\"val\", transform=transform, ds_num=cfg.ds_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=cfg.batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=cfg.n_workers,\n",
    ")\n",
    "val_loader = data.DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=cfg.batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    "    num_workers=cfg.n_workers,\n",
    ")\n",
    "dataloader_dict = {\"train\": train_loader, \"val\": val_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now Starting...\n",
      "\n",
      "\n",
      "========================\n",
      " HYPER PARAMETERS    \n",
      "------------------------\n",
      " Device     >> 0\n",
      " Dataset    >> 24\n",
      " Model      >> Res50\n",
      " Batch size >> 16\n",
      " Epochs     >> 20\n",
      "========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-12-21 11:10:47,834]\u001b[0m Using an existing study with name 'Debug/res50' instead of creating a new one.\u001b[0m\n",
      "[Train] Epoch 12:  55%|████████████████████████████                       | 11/20 [40:43<33:17, 221.97s/it, loss=0.915]"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Train a model\n",
    "    print(\n",
    "        \"\\nNow Starting...\\n\\n\"\n",
    "        \"\\n========================\\n\"\n",
    "        \" HYPER PARAMETERS    \\n\"\n",
    "        \"------------------------\\n\"\n",
    "        \" Device     >> {}\\n\"\n",
    "        \" Dataset    >> {}\\n\"\n",
    "        \" Model      >> {}\\n\"\n",
    "        \" Batch size >> {}\\n\"\n",
    "        \" Epochs     >> {}\\n\"\n",
    "        \"========================\\n\".format(\n",
    "            cfg.device, cfg.ds_num, cfg.model.title(), cfg.batch_size, cfg.n_epochs\n",
    "        )\n",
    "    )\n",
    "    with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "        output_dir = tmp_dir + \"/logs\"\n",
    "        writer = SummaryWriter(output_dir)\n",
    "\n",
    "        # Load weights when using a pre-trained model\n",
    "        if cfg.pretrained:\n",
    "            exp_dir = input(\"Experiment Directory: \")\n",
    "            weight = torch.load(\n",
    "                os.getcwd() + \"/\" + exp_dir + \"/artifacts/models/weight.pth\"\n",
    "            )\n",
    "            model.load_state_dict(weight)\n",
    "\n",
    "        trainer = Trainer(model=model)\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                study = optuna.create_study(\n",
    "                    study_name=cfg.exp_name + \"/\" + cfg.model,\n",
    "                    storage=\"sqlite:///mlruns/{}_{}.db\".format(cfg.exp_name, cfg.model),\n",
    "                    load_if_exists=True,\n",
    "                )\n",
    "                study.optimize(trainer.run, n_trials=cfg.n_trials)\n",
    "                break\n",
    "\n",
    "            except RuntimeError:\n",
    "                break\n",
    "\n",
    "    message = \"\"\"\n",
    "    ========================\n",
    "        TRANING FINISHED\n",
    "    ========================\n",
    "    \"\"\"\n",
    "\n",
    "    modules.line_notify(message)\n",
    "    print(message)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.6.0"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
