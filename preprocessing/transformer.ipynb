{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torchvision import transforms\n",
    "\n",
    "from utils.geometry import project_onto_plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Compose(object):\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, img, label):\n",
    "        for t in self.transforms:\n",
    "            img, label = t(img, label)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scale(object):\n",
    "    def __init__(self, scale: list):\n",
    "        self.scale = scale  # [scale_min, scale_max]\n",
    "\n",
    "    def __call__(self, img, label):\n",
    "        width = img.size[0]\n",
    "        height = img.size[1]\n",
    "\n",
    "        scale = np.random.uniform(self.scale[0], self.scale[1])\n",
    "\n",
    "        scaled_w = int(width * scale)\n",
    "        scaled_h = int(height * scale)\n",
    "\n",
    "        img = img.resize((scaled_w, scaled_h), Image.BICUBIC)\n",
    "\n",
    "        label = label.resize((scaled_w, scaled_h), Image.NEAREST)\n",
    "\n",
    "        if scale > 1.0:\n",
    "            left = scaled_w - width\n",
    "            left = int(np.random.uniform(0, left))\n",
    "\n",
    "            top = scaled_h - height\n",
    "            top = int(np.random.uniform(0, top))\n",
    "\n",
    "            img = img.crop((left, top, left + width, top + height))\n",
    "            label = label.crop((left, top, left + width, top + height))\n",
    "\n",
    "        else:\n",
    "            p_palette = label.copy().getpalette()\n",
    "\n",
    "            img_original = img.copy()\n",
    "            label_original = label.copy()\n",
    "\n",
    "            pad_width = width - scaled_w\n",
    "            pad_width_left = int(np.random.uniform(0, pad_width))\n",
    "\n",
    "            pad_height = height - scaled_h\n",
    "            pad_height_top = int(np.random.uniform(0, pad_height))\n",
    "\n",
    "            img = Image.new(img.mode, (width, height), (0, 0, 0))\n",
    "            img.paste(img_original, (pad_width_left, pad_height_top))\n",
    "\n",
    "            label = Image.new(label.mode, (width, height), (0))\n",
    "            label.paste(label_original, (pad_width_left, pad_height_top))\n",
    "            label.putpalette(p_palette)\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomRotation(object):\n",
    "    def __init__(self, angle):\n",
    "        self.angle = angle\n",
    "\n",
    "    def __call__(self, img, label):\n",
    "        rotate_angle = np.random.uniform(self.angle[0], self.angle[1])\n",
    "        img = img.rotate(rotate_angle, Image.BILINEAR)\n",
    "        label = label.rotate(rotate_angle, Image.NEAREST)\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomMirror(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, img, label):\n",
    "        if np.random.randint(2):\n",
    "            img = ImageOps.mirror(img)\n",
    "            label = ImageOps.mirror(label)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resize(object):\n",
    "    def __init__(self, input_size):\n",
    "        self.input_size = input_size\n",
    "\n",
    "    def __call__(self, img, label):\n",
    "        img = img.resize(self.input_size, Image.BICUBIC)\n",
    "        label = label.resize(self.input_size, Image.NEAREST)\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize_Tensor(object):\n",
    "    def __init__(self, color_mean, color_std):\n",
    "        self.color_mean = color_mean\n",
    "        self.color_std = color_std\n",
    "\n",
    "    def __call__(self, img, label):\n",
    "\n",
    "        img = transforms.functional.to_tensor(img)\n",
    "        img = transforms.functional.normalize(img, self.color_mean, self.color_std)\n",
    "\n",
    "        label = np.array(label)\n",
    "\n",
    "        index = np.where(label == 255)\n",
    "        label[index] = 0\n",
    "\n",
    "        label = torch.from_numpy(label)\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaleTransformer:\n",
    "    def __init__(self, ds_num):\n",
    "\n",
    "        with open(\n",
    "            \"G:/My Drive/hppose/Database/ds_{:03d}/ds_config.yaml\".format(ds_num)\n",
    "        ) as f:\n",
    "            config = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "\n",
    "        camera = config[\"camera\"]\n",
    "        x = camera[\"z_max\"] * np.tan(np.radians(camera[\"fov\"] / 2))\n",
    "        y = x * camera[\"aspect\"]\n",
    "        self.aspect = camera[\"aspect\"]\n",
    "        self.fov = camera[\"fov\"]\n",
    "\n",
    "        # Range of each parameter\n",
    "        X = [-x, x]\n",
    "        Y = [-y, y]\n",
    "        Z = [camera[\"z_min\"], camera[\"z_max\"]]\n",
    "        N = [-1.0, 1.0]\n",
    "        NZ = [0.25, 0.95]\n",
    "        GAMMA = [-1.0, 1.0]\n",
    "        PHI = [0.0, config[\"articulation\"][\"phi_max\"]]\n",
    "\n",
    "        RANGE = np.stack([X, Y, Z, N, N, NZ, GAMMA, GAMMA, PHI], 0)\n",
    "\n",
    "        self.scaler = MinMaxScaler()\n",
    "        self.scaler.fit(RANGE.T)\n",
    "\n",
    "    def transform(self, target):\n",
    "        return self.scaler.transform(target)\n",
    "\n",
    "    def inverse_transform(self, target, size=None):\n",
    "\n",
    "        if isinstance(target, dict):\n",
    "            target_ = (\n",
    "                torch.cat(\n",
    "                    [\n",
    "                        target[\"trans3d\"],\n",
    "                        target[\"orient\"],\n",
    "                        target[\"roll\"],\n",
    "                        target[\"joint\"],\n",
    "                    ],\n",
    "                    dim=1,\n",
    "                )\n",
    "                .cpu()\n",
    "                .detach()\n",
    "                .numpy()\n",
    "            )\n",
    "\n",
    "            target_ = torch.tensor(self.scaler.inverse_transform(target_))\n",
    "\n",
    "            trans2d = target[\"trans2d\"].cpu() * torch.tensor([size])\n",
    "\n",
    "            ret = torch.cat([target_[:, :3], trans2d, target_[:, 3:]], dim=1)\n",
    "\n",
    "        elif target.shape[0] == 1:\n",
    "            target_ = torch.tensor(self.scaler.inverse_transform(target)).squeeze()\n",
    "            trans2d = project_onto_plane(\n",
    "                target_[:3], a_ratio=self.aspect, fov=self.fov, is_batch=False\n",
    "            )\n",
    "            trans2d *= torch.tensor([1920, 1080])\n",
    "            gamma = torch.rad2deg(torch.atan(target_[6] / target_[7])).unsqueeze(0)\n",
    "            ret = torch.cat(\n",
    "                [target_[:3], trans2d, target_[3:6], gamma, target_[8].unsqueeze(0)]\n",
    "            ).numpy()\n",
    "\n",
    "        else:\n",
    "            target_ = torch.tensor(self.scaler.inverse_transform(target)).squeeze()\n",
    "            trans2d = project_onto_plane(\n",
    "                target_[:, :3], a_ratio=self.aspect, fov=self.fov, is_batch=True\n",
    "            )\n",
    "            trans2d *= torch.tensor([1920, 1080])\n",
    "            gamma = (\n",
    "                torch.rad2deg(torch.atan(target_[:, 6] / target_[:, 7])).unsqueeze(0).T\n",
    "            )\n",
    "\n",
    "            ret = torch.cat(\n",
    "                [\n",
    "                    target_[:, :3],\n",
    "                    trans2d,\n",
    "                    target_[:, 3:6],\n",
    "                    gamma,\n",
    "                    target_[:, 8].unsqueeze(0).T,\n",
    "                ],\n",
    "                dim=1,\n",
    "            ).numpy()\n",
    "\n",
    "        return ret"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python",
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.6.0"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
